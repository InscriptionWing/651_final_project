"""
è‹±æ–‡ç‰ˆä¸»ç¨‹åº
ä¸“é—¨ç”¨äºç”Ÿæˆè‹±æ–‡NDISæŠ¤å·¥æ•°æ®
"""

import asyncio
import argparse
import logging
from pathlib import Path
from typing import Optional, Dict, List

from pure_llm_english_generator import PureLLMEnglishGenerator
from english_data_schema import CarerServiceRecord, EnglishDataValidator

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class EnglishCarersDataProject:
    """è‹±æ–‡æŠ¤å·¥æ•°æ®ç”Ÿæˆé¡¹ç›® - çº¯LLMç‰ˆæœ¬"""
    
    def __init__(self):
        """åˆå§‹åŒ–é¡¹ç›®"""
        self.generator = PureLLMEnglishGenerator()
        self.validator = EnglishDataValidator()
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        self._create_directories()
        
        logger.info("English Carers Data Project initialized successfully (Pure LLM mode)")
    
    def _create_directories(self):
        """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
        directories = ["output", "logs", "reports"]
        for directory in directories:
            Path(directory).mkdir(parents=True, exist_ok=True)
    
    async def generate_dataset(self, 
                             size: int = 100, 
                             validate: bool = True,
                             save_formats: List[str] = None) -> Dict:
        """ç”Ÿæˆè‹±æ–‡æ•°æ®é›†"""
        
        if save_formats is None:
            save_formats = ["json", "csv", "jsonl"]
        
        logger.info(f"Starting English dataset generation: {size} records")
        
        try:
            # ç”Ÿæˆæ•°æ®
            records = await self.generator.generate_dataset(size)
            
            if not records:
                raise Exception("No valid records generated")
            
            logger.info(f"Successfully generated {len(records)} English records")
            
            # æ•°æ®éªŒè¯
            validation_result = None
            if validate:
                logger.info("Performing data validation...")
                validation_result = self.validator.validate_data_quality(records)
                logger.info("Basic validation completed")
            
            # ä¿å­˜æ•°æ®é›†
            saved_files = {}
            if "json" in save_formats or "jsonl" in save_formats or "csv" in save_formats:
                saved_files = self.generator.save_dataset(records, "pure_llm_english_carers")
            
            # æ„å»ºç»“æœ
            result = {
                "success": True,
                "records_count": len(records),
                "saved_files": saved_files,
                "validation": validation_result,
                "sample_records": [record.to_dict() for record in records[:3]]  # å‰3ä¸ªä½œä¸ºæ ·æœ¬
            }
            
            return result
            
        except Exception as e:
            logger.error(f"Dataset generation failed: {e}")
            return {
                "success": False,
                "error": str(e),
                "records_count": 0
            }
    
    async def validate_existing_data(self, file_path: str) -> Dict:
        """éªŒè¯ç°æœ‰æ•°æ®æ–‡ä»¶"""
        try:
            import json
            
            with open(file_path, 'r', encoding='utf-8') as f:
                if file_path.endswith('.jsonl'):
                    data = [json.loads(line) for line in f]
                else:
                    data = json.load(f)
            
            # è½¬æ¢ä¸ºCarerServiceRecordå¯¹è±¡
            records = []
            for item in data:
                try:
                    record = CarerServiceRecord(**item)
                    records.append(record)
                except Exception as e:
                    logger.warning(f"Invalid record: {e}")
            
            # æ‰§è¡ŒéªŒè¯
            validation_result = self.validator.validate_data_quality(records)
            
            return {
                "success": True,
                "records_count": len(records),
                "validation": validation_result
            }
            
        except Exception as e:
            logger.error(f"Data validation failed: {e}")
            return {
                "success": False,
                "error": str(e)
            }


async def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description="English NDIS Carers Data Generator (Pure LLM)")
    parser.add_argument("--size", type=int, default=100, 
                       help="Number of records to generate (default: 100)")
    parser.add_argument("--no-validate", action="store_true", 
                       help="Skip data validation")
    parser.add_argument("--validate-file", type=str, 
                       help="Validate existing data file")
    parser.add_argument("--output-formats", nargs="+", 
                       default=["json", "csv", "jsonl"],
                       choices=["json", "csv", "jsonl"],
                       help="Output formats (default: json csv jsonl)")
    
    args = parser.parse_args()
    
    try:
        project = EnglishCarersDataProject()
        
        if args.validate_file:
            # éªŒè¯ç°æœ‰æ–‡ä»¶
            result = await project.validate_existing_data(args.validate_file)
            
            if result["success"]:
                print(f"\nâœ… Data validation completed successfully!")
                print(f"ğŸ“Š Records validated: {result['records_count']}")
                if result.get("validation"):
                    val = result["validation"]
                    print(f"ğŸ“Š Total records: {val.get('total_records', 'N/A')}")
                    print(f"ğŸ‘¥ Unique carers: {val.get('unique_carers', 'N/A')}")
                    print(f"ğŸ¯ Unique participants: {val.get('unique_participants', 'N/A')}")
            else:
                print(f"âŒ Validation failed: {result['error']}")
        
        else:
            # ç”Ÿæˆæ–°æ•°æ®é›†
            result = await project.generate_dataset(
                size=args.size,
                validate=not args.no_validate,
                save_formats=args.output_formats
            )
            
            if result["success"]:
                print(f"\nâœ… English dataset generation completed successfully!")
                print(f"ğŸ“Š Generated records: {result['records_count']}")
                
                if result.get("validation"):
                    val = result["validation"]
                    print(f"ğŸ“Š Total records: {val.get('total_records', 'N/A')}")
                    print(f"ğŸ‘¥ Unique carers: {val.get('unique_carers', 'N/A')}")
                    print(f"ğŸ¯ Unique participants: {val.get('unique_participants', 'N/A')}")
                    print(f"â±ï¸ Average duration: {val.get('avg_duration', 'N/A'):.2f} hours" if val.get('avg_duration') else "â±ï¸ Average duration: N/A")
                    print(f"ğŸ“ Average narrative length: {val.get('avg_narrative_length', 'N/A'):.0f} characters" if val.get('avg_narrative_length') else "ğŸ“ Average narrative length: N/A")
                
                print(f"ğŸ“ Saved files:")
                for format_type, filepath in result["saved_files"].items():
                    print(f"   {format_type}: {filepath}")
                
                # æ˜¾ç¤ºæ ·æœ¬è®°å½•ä¿¡æ¯
                if result.get("sample_records"):
                    sample = result["sample_records"][0]
                    print(f"\nğŸ“‹ Sample record:")
                    print(f"   Carer: {sample.get('carer_name', 'N/A')}")
                    print(f"   Service Type: {sample['service_type']}")
                    print(f"   Duration: {sample['duration_hours']} hours")
                    print(f"   Outcome: {sample['service_outcome']}")
                    print(f"   Location: {sample['location_type']}")
                    print(f"   Narrative: {sample['narrative_notes'][:150]}...")
            
            else:
                print(f"âŒ Generation failed: {result['error']}")
                
    except KeyboardInterrupt:
        print("\nâš ï¸  Generation interrupted by user")
    except Exception as e:
        logger.error(f"Unexpected error: {e}")
        print(f"âŒ Unexpected error: {e}")


if __name__ == "__main__":
    asyncio.run(main())
