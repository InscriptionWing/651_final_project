"""
Hugging Face API æµ‹è¯•è„šæœ¬
ä½¿ç”¨å…è´¹çš„Hugging Face APIç”ŸæˆæŠ¤å·¥æ•°æ®
"""

import asyncio
import json
import logging
import requests
from typing import Dict, Any
from datetime import datetime

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ä»free_configè·å–token
from free_config import FREE_LLM_CONFIG

async def test_huggingface_api():
    """æµ‹è¯•Hugging Face APIè¿æ¥"""
    
    hf_config = FREE_LLM_CONFIG["huggingface"]
    token = hf_config["token"]
    
    if not token or token == "your_huggingface_token_here":
        print("âŒ é”™è¯¯ï¼šHugging Face tokenæœªé…ç½®")
        print("è¯·åœ¨ free_config.py ä¸­è®¾ç½®æ­£ç¡®çš„token")
        return False
    
    # æµ‹è¯•APIè¿æ¥
    api_url = "https://api-inference.huggingface.co/models/gpt2"
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    test_data = {
        "inputs": "The carer provided support to",
        "parameters": {
            "max_length": 100,
            "temperature": 0.7,
            "do_sample": True,
            "return_full_text": False
        }
    }
    
    try:
        print("ğŸ”„ æµ‹è¯•Hugging Face APIè¿æ¥...")
        response = requests.post(api_url, headers=headers, json=test_data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            print("âœ… Hugging Face APIè¿æ¥æˆåŠŸ!")
            print(f"ğŸ“ ç¤ºä¾‹ç”Ÿæˆ: {result}")
            return True
        else:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯ä¿¡æ¯: {response.text}")
            return False
            
    except Exception as e:
        print(f"âŒ è¿æ¥é”™è¯¯: {e}")
        return False

async def generate_with_huggingface(prompt: str) -> str:
    """ä½¿ç”¨Hugging Faceç”Ÿæˆæ–‡æœ¬"""
    
    hf_config = FREE_LLM_CONFIG["huggingface"]
    token = hf_config["token"]
    
    # ä½¿ç”¨GPT-2è¿›è¡Œæ–‡æœ¬ç”Ÿæˆ
    api_url = "https://api-inference.huggingface.co/models/gpt2"
    
    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json"
    }
    
    data = {
        "inputs": prompt,
        "parameters": {
            "max_length": 150,
            "temperature": 0.7,
            "do_sample": True,
            "return_full_text": False,
            "pad_token_id": 50256  # GPT-2çš„pad token
        }
    }
    
    try:
        response = requests.post(api_url, headers=headers, json=data, timeout=30)
        
        if response.status_code == 200:
            result = response.json()
            if isinstance(result, list) and len(result) > 0:
                generated_text = result[0].get("generated_text", "")
                return generated_text.strip()
            return ""
        else:
            logger.error(f"Hugging Face APIé”™è¯¯: {response.status_code} - {response.text}")
            return ""
            
    except Exception as e:
        logger.error(f"Hugging Faceè°ƒç”¨å¤±è´¥: {e}")
        return ""

async def generate_carer_narrative():
    """ç”ŸæˆæŠ¤å·¥æœåŠ¡å™è¿°"""
    
    prompts = [
        "The carer provided personal care support to the participant, assisting with daily hygiene activities.",
        "Today the support worker helped the client with community access activities.",
        "The disability support worker delivered household assistance services.",
        "Professional care was provided to assist the participant with transport needs.",
        "The carer facilitated social support activities for the participant."
    ]
    
    print("\nğŸ¯ ç”ŸæˆæŠ¤å·¥æœåŠ¡å™è¿°ç¤ºä¾‹:")
    print("=" * 50)
    
    for i, prompt in enumerate(prompts, 1):
        print(f"\n{i}. è¾“å…¥æç¤º: {prompt}")
        
        generated = await generate_with_huggingface(prompt)
        
        if generated:
            # ç»„åˆå®Œæ•´å™è¿°
            full_narrative = f"{prompt} {generated}"
            print(f"   ç”Ÿæˆç»“æœ: {full_narrative}")
        else:
            print("   âŒ ç”Ÿæˆå¤±è´¥")

async def test_structured_generation():
    """æµ‹è¯•ç»“æ„åŒ–æ•°æ®ç”Ÿæˆ"""
    
    print("\nğŸ—ï¸ æµ‹è¯•ç»“æ„åŒ–æŠ¤å·¥è®°å½•ç”Ÿæˆ:")
    print("=" * 50)
    
    # æŠ¤å·¥æœåŠ¡è®°å½•æ¨¡æ¿
    service_types = [
        "Personal Care", "Community Access", "Household Tasks", 
        "Transport Assistance", "Social Support"
    ]
    
    outcomes = ["positive", "neutral", "negative"]
    
    for service_type in service_types[:2]:  # æµ‹è¯•å‰ä¸¤ä¸ª
        for outcome in outcomes[:2]:  # æµ‹è¯•å‰ä¸¤ä¸ªç»“æœ
            
            prompt = f"The carer provided {service_type.lower()} support with a {outcome} outcome. The participant"
            
            print(f"\nğŸ”¸ æœåŠ¡ç±»å‹: {service_type}")
            print(f"ğŸ”¸ é¢„æœŸç»“æœ: {outcome}")
            print(f"ğŸ”¸ æç¤º: {prompt}")
            
            generated = await generate_with_huggingface(prompt)
            
            if generated:
                full_text = f"{prompt} {generated}"
                print(f"âœ… ç”Ÿæˆ: {full_text[:100]}...")
                
                # æ¨¡æ‹Ÿåˆ›å»ºJSONè®°å½•
                record = {
                    "service_type": service_type,
                    "service_outcome": outcome,
                    "narrative_notes": full_text[:200],  # é™åˆ¶é•¿åº¦
                    "generated_at": datetime.now().isoformat()
                }
                
                print(f"ğŸ“‹ è®°å½•: {json.dumps(record, indent=2)}")
            else:
                print("âŒ ç”Ÿæˆå¤±è´¥")

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¤— Hugging Face API æµ‹è¯•ç¨‹åº")
    print("=" * 50)
    
    # 1. æµ‹è¯•APIè¿æ¥
    if not await test_huggingface_api():
        print("\nğŸ’¡ è§£å†³æ–¹æ¡ˆ:")
        print("1. è®¿é—® https://huggingface.co/settings/tokens")
        print("2. åˆ›å»ºæ–°çš„ Read æƒé™ token")
        print("3. åœ¨ free_config.py ä¸­æ›´æ–° token")
        return
    
    # 2. ç”Ÿæˆå™è¿°ç¤ºä¾‹
    await generate_carer_narrative()
    
    # 3. æµ‹è¯•ç»“æ„åŒ–ç”Ÿæˆ
    await test_structured_generation()
    
    print("\nğŸ‰ æµ‹è¯•å®Œæˆ!")
    print("æ‚¨ç°åœ¨å¯ä»¥ä½¿ç”¨Hugging Face APIè¿›è¡Œæ•°æ®ç”Ÿæˆäº†ã€‚")

if __name__ == "__main__":
    asyncio.run(main())

